{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05410cf-7ce2-4c0b-b890-8d7b5db30e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from supervoice.tokenizer import Tokenizer\n",
    "from supervoice.model import SupervoiceGPT\n",
    "from train_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643b57d0-a798-4c58-ad76-4e97f417114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "tokenizer = Tokenizer(config, \"tokenizer_text.model\")\n",
    "model = SupervoiceGPT(config)\n",
    "checkpoint = torch.load(f'./output/enc_dec.pt', map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d28b485-c49d-48b8-8ccc-d19b004b670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input\n",
    "# input = torch.tensor([tokenizer.encode(\"What, time?\") + [0,0], tokenizer.encode(\"What, time?\") + [1, 0]])\n",
    "# input_lengths = torch.tensor([len(tokenizer.encode(\"What, time?\")), len(tokenizer.encode(\"What, time?\")) + 1])\n",
    "\n",
    "# # Output\n",
    "# output_tokens = torch.tensor([tokenizer.encode_phonemes([\"<s>\", \"</s>\", \"</s>\"]), tokenizer.encode_phonemes([\"<s>\", \"</s>\", \"</s>\"])])\n",
    "# output_durations = torch.tensor([[0, 1, 3], [0, 1, 3]])\n",
    "# output_lengths = torch.tensor([2, 3])\n",
    "# print(input)\n",
    "# print(output_tokens)\n",
    "# print(output_durations)\n",
    "\n",
    "# model(\n",
    "#     input = input, \n",
    "#     input_lengths = input_lengths,\n",
    "#     output_tokens = output_tokens,\n",
    "#     output_durations = output_durations,\n",
    "#     output_lengths = output_lengths\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd6c7833-e426-4c8b-81e3-364c512bd260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'ɐ', 'ʔ', 'tʰ', 'aj', 'm', 'ɪ', 'z', 'ɪ', 'ʔ', 's', 'tʲ', 'iː', 'v'] [6, 4, 7, 7, 9, 6, 5, 7, 7, 5, 8, 6, 15, 14]\n"
     ]
    }
   ],
   "source": [
    "tokens, durations = model.generate(\"What time is it, Steve?\", tokenizer, max_new_tokens = 64, top_k = 2)\n",
    "print(tokens, durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57115615-639b-4516-ac9b-422561ffed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.8129474520683289\n",
      "•: 0.1863473802804947\n",
      "ʃ: 0.0001916663022711873\n",
      "ɪ: 5.4341042414307594e-05\n",
      "ɛ: 5.219665763434023e-05\n",
      "t: 3.180649582645856e-05\n",
      "tʰ: 2.836522071447689e-05\n",
      "w: 2.3899901862023398e-05\n",
      "ə: 2.033316377492156e-05\n",
      "l: 1.867962782853283e-05\n"
     ]
    }
   ],
   "source": [
    "input = \"What time is it, Steve?\"\n",
    "ctx_tokens = ['w', 'ɐ', 'ʔ', 'tʰ', 'aj', 'm', 'ɪ', 'z', 'ɪ', 'ʔ']\n",
    "ctx_durations = [6, 4, 7, 7, 9, 6, 5, 7, 7, 5]\n",
    "probs, p = model.predict_next(input, ctx_tokens, ctx_durations, tokenizer)\n",
    "for i in range(len(probs)):\n",
    "    print(p[i] + \": \"+ str(probs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d9a12-c68a-4f97-935a-0b4652fbceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
