{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05410cf-7ce2-4c0b-b890-8d7b5db30e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from supervoice.tokenizer import Tokenizer\n",
    "from supervoice.model import SupervoiceGPT\n",
    "from train_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643b57d0-a798-4c58-ad76-4e97f417114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "tokenizer = Tokenizer(config, \"tokenizer_text.model\")\n",
    "model = SupervoiceGPT(config)\n",
    "checkpoint = torch.load(f'./output/enc_dec_fix_phonemes.pt', map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d28b485-c49d-48b8-8ccc-d19b004b670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input\n",
    "# input = torch.tensor([tokenizer.encode(\"What, time?\") + [0,0], tokenizer.encode(\"What, time?\") + [1, 0]])\n",
    "# input_lengths = torch.tensor([len(tokenizer.encode(\"What, time?\")), len(tokenizer.encode(\"What, time?\")) + 1])\n",
    "\n",
    "# # Output\n",
    "# output_tokens = torch.tensor([tokenizer.encode_phonemes([\"<s>\", \"</s>\", \"</s>\"]), tokenizer.encode_phonemes([\"<s>\", \"</s>\", \"</s>\"])])\n",
    "# output_durations = torch.tensor([[0, 1, 3], [0, 1, 3]])\n",
    "# output_lengths = torch.tensor([2, 3])\n",
    "# print(input)\n",
    "# print(output_tokens)\n",
    "# print(output_durations)\n",
    "\n",
    "# model(\n",
    "#     input = input, \n",
    "#     input_lengths = input_lengths,\n",
    "#     output_tokens = output_tokens,\n",
    "#     output_durations = output_durations,\n",
    "#     output_lengths = output_lengths\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6c7833-e426-4c8b-81e3-364c512bd260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ç', 9), ('iː', 7), ('v', 7), ('ɛ', 8), ('ɹ', 8), ('i', 7), ('w', 6), ('ɐ', 5), ('ʔ', 3), ('tʰ', 8), ('aj', 11), ('m', 7), ('ɪ', 6), ('z', 7), ('ɪ', 6), ('ʔ', 8)]\n"
     ]
    }
   ],
   "source": [
    "tokens = model.generate(\"Hey, Vera, what time is it?\", tokenizer, max_new_tokens = 64, top_k = 3)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57115615-639b-4516-ac9b-422561ffed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɹ: 0.4439086318016052\n",
      "j: 0.33370551466941833\n",
      "•: 0.030026810243725777\n",
      "ɑ: 0.01850922219455242\n",
      "w: 0.015319732017815113\n",
      "ə: 0.014852934516966343\n",
      "ɡ: 0.014305449090898037\n",
      "</s>: 0.0077429781667888165\n",
      "ɫ: 0.007389472331851721\n",
      "ɛ: 0.00711129792034626\n"
     ]
    }
   ],
   "source": [
    "input = \"Hey, you?\"\n",
    "ctx_tokens = ['ç', 'ɪ']\n",
    "ctx_durations = [8, 10]\n",
    "probs, p = model.predict_next(input, ctx_tokens, ctx_durations, tokenizer)\n",
    "for i in range(len(probs)):\n",
    "    print(p[i] + \": \"+ str(probs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d9a12-c68a-4f97-935a-0b4652fbceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
